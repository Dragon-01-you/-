import os
import sys
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.document_loaders import TextLoader
from langchain.schema import Document
import shutil

def print_step(step, message):
    """æ‰“å°æ­¥éª¤ä¿¡æ¯"""
    print(f"\n{'='*50}")
    print(f"æ­¥éª¤ {step}: {message}")
    print(f"{'='*50}")

def load_documents(data_path):
    """åŠ è½½æ‰€æœ‰æ–‡æœ¬æ–‡ä»¶"""
    documents = []
    txt_files = []
    
    # éå†æ‰€æœ‰æ–‡ä»¶å¤¹å’Œå­æ–‡ä»¶å¤¹
    for root, dirs, files in os.walk(data_path):
        for file in files:
            if file.endswith(".txt"):
                txt_files.append(os.path.join(root, file))
    
    print(f"æ‰¾åˆ° {len(txt_files)} ä¸ªæ–‡æœ¬æ–‡ä»¶")
    
    for i, file_path in enumerate(txt_files):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
            doc = Document(
                page_content=content,
                metadata={"source": os.path.basename(file_path)}
            )
            documents.append(doc)
            
            print(f"   âœ… å·²åŠ è½½: {os.path.basename(file_path)}")
            
        except Exception as e:
            print(f"   âŒ åŠ è½½å¤±è´¥: {os.path.basename(file_path)} - {str(e)}")
    
    return documents

def main():
    print("ğŸ¯ å¼€å§‹æ„å»ºæ±Ÿè¥¿å·¥ä¸šå·¥ç¨‹èŒä¸šæŠ€æœ¯å­¦é™¢çŸ¥è¯†åº“å‘é‡æ•°æ®åº“")
    
    # æ­¥éª¤1ï¼šæ£€æŸ¥æ•°æ®æ–‡ä»¶å¤¹
    print_step(1, "æ£€æŸ¥æ•°æ®æ–‡ä»¶å¤¹")
    data_path = "æ±Ÿè¥¿å·¥ä¸šå·¥ç¨‹èŒä¸šæŠ€æœ¯å­¦é™¢_æ•°æ®ä»“åº“"
    
    if not os.path.exists(data_path):
        print("âŒ æ•°æ®æ–‡ä»¶å¤¹ä¸å­˜åœ¨")
        return
    
    # æ­¥éª¤2ï¼šåˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨å’ŒåµŒå…¥æ¨¡å‹
    print_step(2, "åˆå§‹åŒ–æ–‡æœ¬å¤„ç†å·¥å…·")
    
    # æ–‡æœ¬åˆ†å‰²å™¨
    text_splitter = CharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50,
        separator="\n"
    )
    
    # åµŒå…¥æ¨¡å‹
    print("æ­£åœ¨åŠ è½½ä¸­æ–‡åµŒå…¥æ¨¡å‹...")
    embeddings = HuggingFaceEmbeddings(
        model_name="GanymedeNil/text2vec-large-chinese"
    )
    print("âœ… åµŒå…¥æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # æ­¥éª¤3ï¼šåŠ è½½æ–‡æ¡£
    print_step(3, "åŠ è½½æ–‡æ¡£")
    documents = load_documents(data_path)
    
    if len(documents) == 0:
        print("âŒ æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•æ–‡æ¡£")
        return
    
    # æ­¥éª¤4ï¼šåˆ†å‰²æ–‡æœ¬
    print_step(4, "åˆ†å‰²æ–‡æœ¬")
    print("æ­£åœ¨åˆ†å‰²æ–‡æœ¬...")
    
    all_texts = []
    for doc in documents:
        texts = text_splitter.split_text(doc.page_content)
        all_texts.extend(texts)
    
    print(f"âœ… æ–‡æœ¬åˆ†å‰²å®Œæˆï¼Œå…±ç”Ÿæˆ {len(all_texts)} ä¸ªæ–‡æœ¬å—")
    
    # æ­¥éª¤5ï¼šæ„å»ºå‘é‡æ•°æ®åº“
    print_step(5, "æ„å»ºå‘é‡æ•°æ®åº“")
    
    # åˆ é™¤æ—§çš„æ•°æ®åº“
    if os.path.exists("./vector_db"):
        shutil.rmtree("./vector_db")
    
    print("æ­£åœ¨æ„å»ºå‘é‡æ•°æ®åº“...")
    
    # åˆ›å»ºå‘é‡æ•°æ®åº“
    vector_db = Chroma.from_texts(
        texts=all_texts,
        embedding=embeddings,
        persist_directory="./vector_db"
    )
    
    # ä¿å­˜æ•°æ®åº“
    vector_db.persist()
    print("âœ… å‘é‡æ•°æ®åº“æ„å»ºå®Œæˆï¼")
    
    # æ­¥éª¤6ï¼šæµ‹è¯•æ£€ç´¢
    print_step(6, "æµ‹è¯•æ£€ç´¢åŠŸèƒ½")
    
    test_queries = [
        "å›¾ä¹¦é¦†",
        "ä¸“ä¸š",
        "å¥–å­¦é‡‘"
    ]
    
    for query in test_queries:
        print(f"\næµ‹è¯•æŸ¥è¯¢: '{query}'")
        try:
            results = vector_db.similarity_search(query, k=1)
            if results:
                content = results[0].page_content
                # æ˜¾ç¤ºå‰100ä¸ªå­—ç¬¦
                preview = content[:100] + "..." if len(content) > 100 else content
                print(f"  æ‰¾åˆ°ç›¸å…³ç»“æœ: {preview}")
            else:
                print("  æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
        except Exception as e:
            print(f"  æ£€ç´¢å¤±è´¥: {str(e)}")
    
    print("\nğŸ‰ å‘é‡æ•°æ®åº“æ„å»ºæˆåŠŸï¼")
    print("ğŸ“ æ•°æ®åº“ä¿å­˜åœ¨: ./vector_db/")
    print('è¯·å›å¤ "å‘é‡æ•°æ®åº“æ„å»ºå®Œæˆ" ç»§ç»­ä¸‹ä¸€æ­¥')

if __name__ == "__main__":
    main()