import os
import requests
import json
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings

class JXIEEQASystem:
    def __init__(self):
        print("ğŸ¯ åˆå§‹åŒ–æ±Ÿè¥¿å·¥ä¸šå·¥ç¨‹èŒä¸šæŠ€æœ¯å­¦é™¢é—®ç­”ç³»ç»Ÿ...")
        
        # åŠ è½½å‘é‡æ•°æ®åº“
        self.embeddings = HuggingFaceEmbeddings(
            model_name="GanymedeNil/text2vec-large-chinese"
        )
        self.vector_db = Chroma(
            persist_directory="./vector_db",
            embedding_function=self.embeddings
        )
        
        # åˆ›å»ºæ£€ç´¢å™¨ï¼ˆä¼˜åŒ–ï¼šé™ä½ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œå¢åŠ å…³è”åŒ¹é…ï¼‰
        self.retriever = self.vector_db.as_retriever(
            search_type="similarity",
            search_kwargs={
                "k": 3,  # å¢åŠ æ£€ç´¢æ•°é‡ï¼Œé¿å…æ¼æ‰¾
                "score_threshold": 0.3  # é™ä½é˜ˆå€¼ï¼Œæé«˜å…³è”æ–‡æ¡£å¬å›ç‡
            }
        )
        
        # Ollamaé…ç½®
        self.ollama_url = "http://localhost:11434/api/generate"
        self.model_name = "deepseek-r1:7b"
        
        # å¯¹è¯å†å²ï¼šæ–°å¢â€œå‰ä¸€è½®æ–‡æ¡£æ¥æºâ€å­˜å‚¨ï¼Œç”¨äºè¿½é—®å…³è”
        self.chat_history = []
        self.last_sources = []  # ä¿å­˜å‰ä¸€è½®æ£€ç´¢åˆ°çš„æ–‡æ¡£æ¥æºï¼ˆå¦‚["å¥–å­¦é‡‘.txt"]ï¼‰
        
        print("âœ… é—®ç­”ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
        print(f"ğŸ¤– å·²è¿æ¥Ollamaæ¨¡å‹: {self.model_name}")
        print("ğŸ’¡ æ”¯æŒè¿ç»­è¿½é—®ï¼ˆå¦‚å…ˆé—®'å¥–å­¦é‡‘'ï¼Œå†é—®'é‚£åŠ©å­¦é‡‘å‘¢ï¼Ÿ'ï¼‰")
        print("ğŸ’¡ è¾“å…¥'é€€å‡º'ç»“æŸï¼Œè¾“å…¥'æ¸…ç©ºå†å²'é‡ç½®å¯¹è¯è®°å½•")
    
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²å’Œå‰ä¸€è½®æ¥æº"""
        self.chat_history = []
        self.last_sources = []
        return "âœ… å¯¹è¯å†å²å·²æ¸…ç©ºï¼Œå¯é‡æ–°å¼€å§‹æé—®"
    
    def search_documents(self, question):
        """ä¼˜åŒ–æ£€ç´¢ï¼šè¿½é—®æ—¶ä¼˜å…ˆå…³è”å‰ä¸€è½®æ–‡æ¡£æ¥æº"""
        try:
            # å¦‚æœæœ‰å‰ä¸€è½®æ¥æºï¼Œæ£€ç´¢æ—¶ä¼˜å…ˆåŒ¹é…è¿™äº›æ¥æºçš„æ–‡æ¡£
            if self.last_sources:
                # æ‹¼æ¥â€œå†å²æ¥æº+å½“å‰é—®é¢˜â€ä½œä¸ºæ£€ç´¢å…³é”®è¯ï¼Œå¢å¼ºå…³è”
                enhanced_question = f"åŸºäº{', '.join(self.last_sources)}æ–‡æ¡£ï¼Œå›ç­”ï¼š{question}"
                docs = self.retriever.invoke(enhanced_question)
                # è‹¥å…³è”æ£€ç´¢åˆ°ç»“æœï¼Œç›´æ¥è¿”å›ï¼›è‹¥æ— ï¼Œå†ç”¨åŸé—®é¢˜æ£€ç´¢
                if docs:
                    return docs
            
            # æ— å†å²æ¥æºæˆ–å…³è”æ£€ç´¢å¤±è´¥ï¼Œç”¨åŸé—®é¢˜æ£€ç´¢
            return self.retriever.invoke(question)
        except Exception as e:
            print(f"âŒ æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def format_context(self, docs):
        """æ ¼å¼åŒ–ä¸Šä¸‹æ–‡ï¼ŒåŒæ—¶æ›´æ–°å‰ä¸€è½®æ–‡æ¡£æ¥æº"""
        context = ""
        current_sources = []  # è®°å½•å½“å‰è½®çš„æ–‡æ¡£æ¥æº
        for i, doc in enumerate(docs):
            content = doc.page_content
            source = doc.metadata.get('source', 'æœªçŸ¥æ¥æº')
            current_sources.append(source)
            context += f"ã€èµ„æ–™{i+1} - æ¥æºï¼š{source}ã€‘\n{content}\n\n"
        
        # æ›´æ–°â€œå‰ä¸€è½®æ¥æºâ€ï¼Œç”¨äºä¸‹ä¸€æ¬¡è¿½é—®å…³è”
        self.last_sources = current_sources
        return context
    
    def ask_ollama(self, prompt):
        """è°ƒç”¨Ollama APIç”Ÿæˆå›ç­”"""
        try:
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.5,
                    "top_p": 0.8,
                    "num_predict": 1000,
                    "num_ctx": 2048  # æ‰©å¤§ä¸Šä¸‹æ–‡çª—å£ï¼Œé€‚é…æ›´é•¿çš„å†å²å…³è”
                }
            }
            
            response = requests.post(
                self.ollama_url,
                json=payload,
                timeout=300
            )
            
            if response.status_code == 200:
                return response.json().get("response", "âŒ æ¨¡å‹è¿”å›ä¸ºç©º")
            else:
                return f"âŒ Ollama APIè°ƒç”¨å¤±è´¥: {response.status_code}\nå“åº”: {response.text}"
                
        except requests.exceptions.ConnectionError:
            return "âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ï¼Œè¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œ"
        except Exception as e:
            return f"âŒ è°ƒç”¨Ollamaæ¨¡å‹å¤±è´¥: {str(e)}"
    
    def smart_qa(self, question):
        """æ™ºèƒ½é—®ç­”ï¼šä¼˜åŒ–è¿½é—®å…³è”ï¼Œä¼˜å…ˆä»å†å²æ–‡æ¡£æ‰¾ä¿¡æ¯"""
        print(f"\nğŸ” æ­£åœ¨æœç´¢ç›¸å…³èµ„æ–™...")
        
        try:
            # å¤„ç†ç‰¹æ®ŠæŒ‡ä»¤
            if question.strip() == "æ¸…ç©ºå†å²":
                return self.clear_history()
            
            # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼ˆå·²ä¼˜åŒ–ï¼šå…³è”å‰ä¸€è½®æ¥æºï¼‰
            docs = self.search_documents(question)
            if not docs:
                return "âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å­¦æ ¡èµ„æ–™"
            print(f"âœ… æ‰¾åˆ° {len(docs)} æ¡ç›¸å…³è®°å½•")
            
            # 2. æ ¼å¼åŒ–ä¸Šä¸‹æ–‡ï¼ˆæ›´æ–°å‰ä¸€è½®æ¥æºï¼‰
            context = self.format_context(docs)
            all_sources = self.last_sources  # ç›´æ¥ç”¨å½“å‰è½®çš„æ¥æº
            
            # 3. æ‹¼æ¥å¯¹è¯å†å²ï¼ˆå¼ºè°ƒè¿½é—®éœ€å…³è”å‰ä¸€è½®èµ„æ–™ï¼‰
            history_str = ""
            if self.chat_history:
                recent_history = self.chat_history[-3:]  # ä¿ç•™æœ€è¿‘3è½®ï¼Œé¿å…è¿‡è½½
                for h in recent_history:
                    history_str += f"ç”¨æˆ·ä¹‹å‰é—®ï¼š{h['question']}\nåŠ©æ‰‹ä¹‹å‰ç­”ï¼š{h['answer']}\n\n"
            
            # 4. ä¼˜åŒ–æç¤ºè¯ï¼šå¼ºåˆ¶æ¨¡å‹ä¼˜å…ˆä»å†å²å…³è”çš„èµ„æ–™ä¸­æ‰¾ä¿¡æ¯
            prompt = f"""ä½ æ˜¯æ±Ÿè¥¿å·¥ä¸šå·¥ç¨‹èŒä¸šæŠ€æœ¯å­¦é™¢çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œå¿…é¡»æŒ‰ä»¥ä¸‹ä¼˜å…ˆçº§å›ç­”ï¼š
1. å…ˆä»ã€Œå¯¹è¯å†å²æåˆ°çš„èµ„æ–™ã€ï¼ˆå¦‚ä¹‹å‰çš„å¥–å­¦é‡‘.txtï¼‰ä¸­æå–å½“å‰é—®é¢˜çš„ä¿¡æ¯ï¼›
2. å†ç»“åˆã€Œå½“å‰æ£€ç´¢åˆ°çš„èµ„æ–™ã€è¡¥å……ï¼›
3. ç¦æ­¢å¿½ç•¥å†å²èµ„æ–™ï¼Œç›´æ¥è¯´â€œæ²¡æ‰¾åˆ°â€ã€‚

ã€å¯¹è¯å†å²ã€‘
{history_str}

ã€å½“å‰æ£€ç´¢åˆ°çš„èµ„æ–™ï¼ˆå«æ¥æºï¼‰ã€‘
{context}

ã€å½“å‰ç”¨æˆ·é—®é¢˜ã€‘
{question}

å›ç­”è¦æ±‚ï¼š
1. è‹¥å†å²èµ„æ–™ï¼ˆå¦‚å¥–å­¦é‡‘.txtï¼‰ä¸­æœ‰å½“å‰é—®é¢˜çš„ä¿¡æ¯ï¼Œå¿…é¡»ä¼˜å…ˆå¼•ç”¨ï¼›
2. åˆ†ç‚¹è¯´æ˜ï¼Œæ˜ç¡®åŒºåˆ†â€œå†å²èµ„æ–™ä¿¡æ¯â€å’Œâ€œå½“å‰æ–°èµ„æ–™ä¿¡æ¯â€ï¼ˆå¦‚æœ‰ï¼‰ï¼›
3. èµ„æ–™æ— ç›¸å…³ä¿¡æ¯æ—¶ï¼Œæ‰å›å¤â€œèµ„æ–™ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯â€ï¼›
4. æœ€åè¡¥å……â€œä¿¡æ¯æ¥æºäºï¼š{', '.join(all_sources)}â€ã€‚

è¯·å¼€å§‹å›ç­”ï¼š"""
            
            # 5. ç”Ÿæˆå›ç­”å¹¶ä¿å­˜å†å²
            print("ğŸ¤– æ­£åœ¨ç”Ÿæˆæ™ºèƒ½å›ç­”...")
            answer = self.ask_ollama(prompt)
            self.chat_history.append({
                "question": question,
                "answer": answer
            })
            
            return f"ğŸ’¡ æ™ºèƒ½å›ç­”ï¼š\n{answer}\n"
            
        except Exception as e:
            return f"âŒ é—®ç­”è¿‡ç¨‹å‡ºé”™: {str(e)}"
    
    def simple_qa(self, question):
        """ç®€åŒ–ç‰ˆé—®ç­”ï¼ˆåªè¿”å›æ£€ç´¢ç»“æœï¼‰"""
        print(f"\nğŸ” æ­£åœ¨æœç´¢ç›¸å…³èµ„æ–™...")
        try:
            docs = self.search_documents(question)
            if not docs:
                return "âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å­¦æ ¡èµ„æ–™"
            
            print(f"âœ… æ‰¾åˆ° {len(docs)} æ¡ç›¸å…³è®°å½•ï¼š")
            result = "åŸºäºå­¦æ ¡èµ„æ–™ï¼Œæ‰¾åˆ°ä»¥ä¸‹ç›¸å…³ä¿¡æ¯ï¼š\n\n"
            for i, doc in enumerate(docs, 1):
                content = doc.page_content
                source = doc.metadata.get('source', 'æœªçŸ¥æ¥æº')
                result += f"ã€ä¿¡æ¯{i} - æ¥æºï¼š{source}ã€‘\n{content}\n{'='*50}\n\n"
                print(f"   ğŸ“„ ä¿¡æ¯{i}: {content[:100]}...")
            return result
        except Exception as e:
            return f"âŒ æœç´¢å¤±è´¥: {str(e)}"

def test_ollama_connection():
    """æµ‹è¯•Ollamaè¿æ¥"""
    print("ğŸ”§ æµ‹è¯•Ollamaè¿æ¥...")
    try:
        response = requests.get("http://localhost:11434/api/tags")
        if response.status_code == 200:
            models = response.json()
            print("âœ… Ollamaè¿æ¥æˆåŠŸï¼")
            print("ğŸ“‹ å¯ç”¨æ¨¡å‹ï¼š")
            for model in models.get('models', []):
                print(f"   - {model['name']}")
            return True
        else:
            print("âŒ æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨")
            return False
    except Exception as e:
        print(f"âŒ Ollamaè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿ï¼š")
        print("   1. OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ")
        print("   2. DeepSeekæ¨¡å‹å·²ä¸‹è½½ï¼ˆè¿è¡Œ: ollama pull deepseek-r1:7bï¼‰")
        print("   3. æœåŠ¡åœ°å€æ˜¯ http://localhost:11434")
        return False

def main():
    ollama_available = test_ollama_connection()
    qa_system = JXIEEQASystem()
    
    print("\n" + "="*60)
    print("ğŸ“ æ±Ÿè¥¿å·¥ä¸šå·¥ç¨‹èŒä¸šæŠ€æœ¯å­¦é™¢æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
    print("="*60)
    if ollama_available:
        print("âœ… æ™ºèƒ½æ¨¡å¼ï¼šæ£€ç´¢ + AIç”Ÿæˆå›ç­”ï¼ˆä¼˜åŒ–è¿½é—®å…³è”ï¼‰")
    else:
        print("âš ï¸  ç®€åŒ–æ¨¡å¼ï¼šåªæ˜¾ç¤ºæ£€ç´¢ç»“æœ")
    print("æ”¯æŒçš„é—®é¢˜ç±»å‹ï¼šå¥–å­¦é‡‘ã€åŠ©å­¦é‡‘ã€å›¾ä¹¦é¦†ã€ä¸“ä¸šè®¾ç½®ç­‰")
    print("="*60)
    
    while True:
        try:
            question = input("\nâ“ è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼ˆè¾“å…¥'é€€å‡º'ç»“æŸï¼‰: ").strip()
            if question.lower() in ['é€€å‡º', 'exit', 'quit']:
                print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
                break
            if not question:
                continue
            
            answer = qa_system.smart_qa(question) if ollama_available else qa_system.simple_qa(question)
            print(f"\n{answer}")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    main()